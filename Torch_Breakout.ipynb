{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, Function\n",
    "import torchvision.transforms as T\n",
    "import ale\n",
    "\n",
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, max_memory=100, discount=.9):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = []\n",
    "        self.discount = discount\n",
    "\n",
    "    def push(self, states, game_over):\n",
    "        self.memory.append([states, game_over])\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[0]\n",
    "\n",
    "\n",
    "    def sample(self, model, sessions=5, session_size=20, queue_size=1):\n",
    "        len_memory = len(self.memory)\n",
    "        num_actions = model.output_shape[-1]\n",
    "\n",
    "        Oin = None\n",
    "        Otar = None\n",
    "        \n",
    "        for i, idx in enumerate(np.random.randint(queue_size, len_memory-session_size,\n",
    "                                                  size=min(len_memory-session_size - queue_size, sessions))):\n",
    "\n",
    "            mems = self.memory[idx - (queue_size - 1):idx+session_size]\n",
    "            counter_sess = 0 - (queue_size - 1)\n",
    "            model.reset_queue()\n",
    "            for mem in mems:\n",
    "                state_t, action_t, reward_t, state_tp1 = mem[0]\n",
    "                game_over = mem[1]\n",
    "                inputs = state_t\n",
    "                temp_state_t = Variable(torch.from_numpy(state_t).type(Tensor))\n",
    "                temp_state_tp1 = Variable(torch.from_numpy(state_tp1).type(Tensor))\n",
    "                \n",
    "                # There should be no target values for actions not taken.\n",
    "                # Thou shalt not correct actions not taken #deep\n",
    "                targets = model(temp_state_t).data.numpy()[0]\n",
    "                counter_sess += 1\n",
    "                if counter_sess >= 0:\n",
    "                    temp_queue = model.save_queue()\n",
    "                    Q_sa = model(temp_state_tp1).data.max(1)[0].view(1, 1).numpy()[0][0]\n",
    "                    model.load_queue(temp_queue)\n",
    "\n",
    "                    if game_over:  # if game_over is True\n",
    "                        targets[action_t] = reward_t\n",
    "                    else:\n",
    "                        # reward_t + gamma * max_a' Q(s', a')\n",
    "                        targets[action_t] = reward_t + self.discount * Q_sa\n",
    "                    if Oin is None:\n",
    "                        Oin = inputs\n",
    "                        Otar = np.expand_dims(targets, axis=0)\n",
    "                    else:\n",
    "                        Oin = np.concatenate([Oin, inputs], axis=0)\n",
    "                        Otar = np.concatenate([Otar, np.expand_dims(targets, axis=0)], axis=0)\n",
    "                \n",
    "            \n",
    "        return Oin, Otar\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class fifo_queue(Function):\n",
    "    def forward(self, old_queue, inputs):\n",
    "        outputs = None\n",
    "        queue = old_queue.clone()\n",
    "        for temp in inputs:\n",
    "            queue = torch.cat((queue, temp.unsqueeze(0)), 0)\n",
    "            queue = queue[1:]\n",
    "            if outputs is None:\n",
    "                outputs = queue.clone().unsqueeze(0)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, queue.unsqueeze(0)), 0)\n",
    "        return outputs, queue\n",
    "    \n",
    "    def backward(self, output_grad, bad_boi):\n",
    "        \n",
    "        # I DONT KNOW WHAT BAD BOI DOES\n",
    "        #print(bad_boi)\n",
    "        return bad_boi[-1], output_grad[:,-1]\n",
    "\n",
    "\n",
    "class Queue(nn.Module):\n",
    "    def __init__(self, input_features, out_features, queue_size, bias=None):\n",
    "        super(Queue, self).__init__()\n",
    "        # Setup the Queue\n",
    "        self.input_features = input_features\n",
    "        self.queue_size = queue_size\n",
    "        self.reset_queue()\n",
    "        \n",
    "        # Init the queue function\n",
    "        self.fifo_queue = fifo_queue()\n",
    "\n",
    "        # Setup the weights to be used in the linear function later. \n",
    "        self.weight = Parameter(torch.Tensor(out_features, input_features*queue_size).type(FloatTensor))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features).type(FloatTensor))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        # Init the parameters\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        # The actual call that is run when you pass data into this model. \n",
    "        output, self.queue = self.fifo_queue(self.queue, inputs)\n",
    "        \n",
    "        #Flatten the queue\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        \n",
    "        # Linear layer built into this layer. \n",
    "        return F.linear(output, self.weight, self.bias)\n",
    "            \n",
    "    # reunit the queue\n",
    "    def reset_queue(self):\n",
    "        \n",
    "        if type(self.input_features) is list:\n",
    "            queue = Variable(torch.zeros([self.queue_size]+self.input_features).type(FloatTensor))\n",
    "        else:\n",
    "            queue = Variable(torch.zeros([self.queue_size]+[self.input_features]).type(FloatTensor))\n",
    "        self.queue = queue\n",
    "        # Not sure if needed\n",
    "        self.queue.requires_grad = False\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Queued_DQN(nn.Module):\\n    def __init__(self, input_size, hidden_size, num_actions, queue_size):\\n        super(Queued_DQN, self).__init__()\\n        self.queue = Queue(input_size, input_size*queue_size, queue_size)\\n        #self.lin1 = nn.Linear(input_size*queue_size, hidden_size)\\n        self.lin2 = nn.Linear(hidden_size, hidden_size)\\n        self.lin3 = nn.Linear(hidden_size, num_actions)\\n        self.output_shape = [1, num_actions]\\n        \\n    def forward(self, x):\\n        # Replace queue with another Linear and you \\n        # have the same network we use for everything else. \\n        # This is the model\\n        x = F.relu(self.queue(x))\\n        #x = F.relu(self.lin1(x))\\n        x = F.relu(self.lin2(x))\\n        x = self.lin3(x)\\n        return x\\n    \\n    def reset_queue(self):\\n        self.queue.reset_queue()\\n        \\n    def save_queue(self):\\n        return self.queue.queue.clone()\\n        \\n    def load_queue(self, input_queue):\\n        self.queue.queue = input_queue.clone() '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Queued_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_actions, queue_size):\n",
    "        super(Queued_DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.queue = Queue(1296, 1296*queue_size, queue_size)\n",
    "        #self.lin1 = nn.Linear(input_size*queue_size, hidden_size)\n",
    "        #self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3 = nn.Linear(1296*queue_size, num_actions)\n",
    "        self.output_shape = [1, num_actions]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Replace queue with another Linear and you \n",
    "        # have the same network we use for everything else. \n",
    "        # This is the model\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.queue(x))\n",
    "        #x = F.relu(self.lin1(x))\n",
    "        #x = F.relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_queue(self):\n",
    "        self.queue.reset_queue()\n",
    "        \n",
    "    def save_queue(self):\n",
    "        return self.queue.queue.clone()\n",
    "        \n",
    "    def load_queue(self, input_queue):\n",
    "        self.queue.queue = input_queue.clone()\n",
    "        \n",
    "\"\"\"class Queued_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_actions, queue_size):\n",
    "        super(Queued_DQN, self).__init__()\n",
    "        self.queue = Queue(input_size, input_size*queue_size, queue_size)\n",
    "        #self.lin1 = nn.Linear(input_size*queue_size, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3 = nn.Linear(hidden_size, num_actions)\n",
    "        self.output_shape = [1, num_actions]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Replace queue with another Linear and you \n",
    "        # have the same network we use for everything else. \n",
    "        # This is the model\n",
    "        x = F.relu(self.queue(x))\n",
    "        #x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_queue(self):\n",
    "        self.queue.reset_queue()\n",
    "        \n",
    "    def save_queue(self):\n",
    "        return self.queue.queue.clone()\n",
    "        \n",
    "    def load_queue(self, input_queue):\n",
    "        self.queue.queue = input_queue.clone() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def train_catch(catch, model, exp_replay, num_games, session_size, sessions,\n",
    "                per_random_act=.1, num_actions=3, queue_size=1, \n",
    "                test_every=None, test_on_games=100):\n",
    "    \n",
    "    # Pytorch Adagrad Optimizer linked with the model\n",
    "    optimizer = optim.Adagrad(model.parameters())\n",
    "\n",
    "    # Set up the return Loss and Scores dataframes\n",
    "    rLoss = pd.DataFrame(columns = ['epoch', 'loss'])\n",
    "    rLoss['epoch'] = rLoss['epoch'].astype(int)\n",
    "\n",
    "    if test_every is not None:\n",
    "        rScores = pd.DataFrame(columns = ['epoch', str('mean score over ' + str(test_on_games) + ' games')])\n",
    "        rScores['epoch'] = rLoss['epoch'].astype(int)\n",
    "        \n",
    "    # Record variables for training\n",
    "    game_cnt = 0\n",
    "    timestep = 0.0\n",
    "    counter = 0\n",
    "    after_first_ball = False\n",
    "    \n",
    "    pushed = 0\n",
    "    \n",
    "    #train over total epochs\n",
    "    for e in range(num_games):\n",
    "\n",
    "        game_over = False\n",
    "        tot_loss = 0.0\n",
    "\n",
    "        # get initial input\n",
    "        input_t = catch.observe(flatten=False, expand_dim=True)\n",
    "    \n",
    "        #iterate over each game\n",
    "        while not game_over:\n",
    "            # t_-1 is the previous observation\n",
    "            input_tm1 = input_t.copy()\n",
    "            \n",
    "            # Calculate next action\n",
    "            temp = torch.from_numpy(input_tm1).type(Tensor)\n",
    "            temp = Variable(temp)\n",
    "            q = model(temp).data.max(1)[1].view(1, 1).numpy()\n",
    "            \n",
    "            # Randomly pick an action, or use the \n",
    "            # Preciously calculated action\n",
    "            if np.random.rand() <= per_random_act:\n",
    "                action = torch.rand(1) * (num_actions)\n",
    "                action = int(action.numpy()[0])\n",
    "            else:\n",
    "                action = q[0][0]\n",
    "                \n",
    "            # apply action, get rewards and new state\n",
    "            reward, timestep, game_over = catch.act(action-1)\n",
    "            # t_0, current timestep\n",
    "            input_t = catch.observe(flatten=False, expand_dim=True)\n",
    "            \n",
    "            # store experience\n",
    "            exp_replay.push(states=[input_tm1, action, reward, input_t], game_over=game_over)\n",
    "            # game has completed, add one to the total game count\n",
    "            if game_over:\n",
    "                game_cnt += 1\n",
    "                \n",
    "            pushed = pushed + 1\n",
    "                \n",
    "            # adapt model\n",
    "            if pushed >= session_size*sessions*2 + 1: \n",
    "                temp_queue = model.save_queue()\n",
    "                \n",
    "                model.reset_queue()\n",
    "                inputs, expected_targets = exp_replay.sample(model, \n",
    "                                                             sessions=sessions, \n",
    "                                                             session_size=session_size, \n",
    "                                                             queue_size=queue_size)\n",
    "\n",
    "                model.reset_queue()\n",
    "                targets = model(Variable(torch.from_numpy(inputs).type(FloatTensor)))\n",
    "\n",
    "                expected_targets = Variable(torch.from_numpy(expected_targets).type(FloatTensor))\n",
    "                \n",
    "                # Compute Huber loss\n",
    "                loss = F.smooth_l1_loss(targets, expected_targets)\n",
    "                tot_loss = tot_loss + loss.data.numpy()[0]\n",
    "                # Optimize the model\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-1, 1)\n",
    "                optimizer.step()\n",
    "\n",
    "                model.load_queue(temp_queue)\n",
    "\n",
    "            \n",
    "\n",
    "        if pushed >= session_size*sessions*2 + 1:\n",
    "            # Save and report loss\n",
    "            rLoss.loc[len(rLoss), :] = [int(e),loss]\n",
    "            print(\"Epoch {:03d} | Loss {:.4f}\".format(e, tot_loss))\n",
    "            # Create initial start environment\n",
    "            \n",
    "        # Reset Game and Model Queue when the game is over. \n",
    "        catch.reset()\n",
    "        model.reset_queue()\n",
    "        \n",
    "        # Test the current model weights if need be.\n",
    "        if (test_every is not None) and ((e + 1) % test_every == 0):\n",
    "\n",
    "            scores = test_catch(\n",
    "                catch=catch, model=model, \n",
    "                test_on_games=test_on_games)\n",
    "\n",
    "            # Save and report mean Score\n",
    "            ms = scores['score'].mean()\n",
    "            rScores.loc[len(rScores), :] = [int(e), ms]\n",
    "            print(\"Epoch {:03d} | MeanScore {:.2f}\".format(e, ms))\n",
    "\n",
    "            catch.reset()\n",
    "\n",
    "    # Return rLoss, and rScores if the user requested the model to be tested\n",
    "    # while training.\n",
    "    if (test_every is not None):\n",
    "        return rLoss, rScores\n",
    "    else:\n",
    "        return rLoss\n",
    "\n",
    "\n",
    "\n",
    "def test_catch(catch, model, test_on_games=100,  save_frames=False):\n",
    "\n",
    "    if save_frames:\n",
    "        frames_stack = []\n",
    "    scores = pd.DataFrame(columns=['game', 'score'])\n",
    "    scores['game'] = scores['game'].astype(int)\n",
    "    # Iterate over number of games to play\n",
    "    for game_num in range(test_on_games):\n",
    "\n",
    "        # Count for num balls that reached the end\n",
    "        game_over = False\n",
    "\n",
    "        # Get initial Frame\n",
    "        frame_num = 1\n",
    "        input_t = catch.observe(flatten=False, expand_dim=True)\n",
    "        if save_frames:\n",
    "            frames_stack.append(input_t)\n",
    "\n",
    "        total_score = 0\n",
    "        # Iterate until end of testing game\n",
    "        while not game_over:\n",
    "\n",
    "            input_tm1 = input_t\n",
    "\n",
    "            # Get next action\n",
    "            temp = torch.from_numpy(input_tm1).type(FloatTensor)\n",
    "            temp = Variable(temp)\n",
    "            q = model(temp).data.max(1)[1].view(1, 1).numpy()\n",
    "            action = q[0][0]\n",
    "\n",
    "            # apply action, get rewards and new state\n",
    "            reward, timestep, game_over = catch.act(action-1)\n",
    "            input_t = catch.observe(flatten=False, expand_dim=True)\n",
    "            total_score += reward\n",
    "            # Iterate frame number\n",
    "            frame_num += 1\n",
    "\n",
    "            if save_frames:\n",
    "                frames_stack.append(input_t)\n",
    "                \n",
    "        scores.loc[len(scores), :] = [int(game_num), total_score]\n",
    "        #scores.append([game_num, total_score])\n",
    "        game_num += 1\n",
    "        catch.reset()\n",
    "        model.reset_queue()\n",
    "\n",
    "    if save_frames:\n",
    "        return scores, frames_stack\n",
    "    else:\n",
    "        return scores\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonjacques/anaconda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "sess_size=10\n",
    "sess = 5\n",
    "\n",
    "q_size = 4\n",
    "i=0\n",
    "\n",
    "test_name = \"RUN\" + str(i) + \"_Q\" + str(q_size)+\"_breakout\"\n",
    "\n",
    "breakout = ale.AleEnv(\"breakout.a26\", game_over_conditions={\"lives\":2,\"episodes\":200}, \n",
    "                      frame_skip=4, screen_color='gray', \n",
    "                      min_action_set=True, reduce_screen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 84 4\n"
     ]
    }
   ],
   "source": [
    "exp = ReplayMemory(max_memory=1000)\n",
    "\n",
    "width = breakout.width\n",
    "height = breakout.height\n",
    "\n",
    "num_actions = len(breakout.actions)\n",
    "\n",
    "print(width, height, num_actions)\n",
    "\n",
    "hidden_size = width * height\n",
    "\n",
    "model = Queued_DQN(hidden_size, hidden_size*q_size, num_actions, q_size)\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakout.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonjacques/anaconda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss 28.8966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b485eed1dfc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m loss, test_on_train = train_catch(catch = breakout, model = model, exp_replay = exp, num_games = 500, per_random_act=.33,\n\u001b[0;32m----> 2\u001b[0;31m                                   test_every = 50, test_on_games = 100, session_size=sess_size, sessions=sess, queue_size=q_size)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbreakout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_catch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreakout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_on_games\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-7dce05fac247>\u001b[0m in \u001b[0;36mtrain_catch\u001b[0;34m(catch, model, exp_replay, num_games, session_size, sessions, per_random_act, num_actions, queue_size, test_every, test_on_games)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                                              \u001b[0msessions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                                              \u001b[0msession_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                                              queue_size=queue_size)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-71abf17ea7a1>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, model, sessions, session_size, queue_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcounter_sess\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mtemp_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0mQ_sa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_state_tp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ff9a2c103385>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#x = F.relu(self.lin1(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#x = F.relu(self.lin2(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d5f4218acae4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Linear layer built into this layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# reunit the queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim_tensor1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim_tensor2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmm\u001b[0;34m(self, matrix)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mAddmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss, test_on_train = train_catch(catch = breakout, model = model, exp_replay = exp, num_games = 500, per_random_act=.33,\n",
    "                                  test_every = 50, test_on_games = 100, session_size=sess_size, sessions=sess, queue_size=q_size)\n",
    "breakout.reset()\n",
    "\n",
    "tests = test_catch(catch = breakout, model = model, test_on_games = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\".//configs\", exist_ok=True)\n",
    "os.makedirs(\".//data\", exist_ok=True)\n",
    "os.makedirs(\".//figs\", exist_ok=True)\n",
    "\n",
    "torch.save(model, \"configs//\" + test_name + \".pt\")\n",
    "loss.to_csv(\"data//\" + test_name + \"_loss.csv\", index=False)\n",
    "test_on_train.to_csv(\"data//\" + test_name + \"_tests_in_training.csv\", index=False)\n",
    "tests.to_csv(\"data//\" + test_name + \"_tests.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"configs//\" + test_name + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       " array([[-0.01113155,  0.02911727, -0.00065977,  0.00394386],\n",
       "        [-0.02103461, -0.02210965,  0.0265988 ,  0.00849212],\n",
       "        [-0.02237904, -0.02285606,  0.02704065,  0.0142559 ],\n",
       "        [-0.02158727, -0.02220373,  0.02559841,  0.0099347 ],\n",
       "        [-0.02230541, -0.02113417,  0.03136184,  0.01512389],\n",
       "        [-0.01932661, -0.02191391,  0.02813921,  0.01295937],\n",
       "        [-0.00233078,  0.00089694,  0.02813921,  0.00447616]], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.sample(model, \n",
    "          sessions=sess, \n",
    "          session_size=sess_size, \n",
    "          queue_size=q_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  True],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "exp.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False], [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False], [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(q_size, len(exp.memory)-sess_size,\n",
    "                                                  size=min(len(exp.memory)-sess_size - q_size, sess)):\n",
    "    print(exp.memory[i - (q_size - 1):i - (q_size - 1)+sess_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 35, 54, 21, 88])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(q_size, len(exp.memory)-sess_size,\n",
    "                                                  size=min(len(exp.memory)-sess_size - q_size, sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = nn.Conv2d(16, 32, kernel_size=4, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakout.observe(flatten=False, expand_dim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
