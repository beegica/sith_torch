{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, Function\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import ale\n",
    "\n",
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "IntTensor = torch.cuda.IntTensor if use_cuda else torch.IntTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class ReplayMemory(object):\\n    \\n    def __init__(self, max_memory=100):\\n        self.max_memory = max_memory\\n        self.memory = []\\n        self.discount = Tensor([discount])\\n\\n    def push(self, states, game_over):\\n        self.memory.append([states, game_over])\\n        if len(self.memory) > self.max_memory:\\n            del self.memory[0]\\n\\n\\n    def sample(self, model, sessions=5, session_size=20, queue_size=1):\\n        len_memory = len(self.memory)\\n        num_actions = model.output_shape[-1]\\n\\n        Oin = None\\n        Otar = None\\n        \\n        for i, idx in enumerate(np.random.randint(queue_size, len_memory-session_size,\\n                                                  size=min(len_memory-session_size - queue_size, sessions))):\\n\\n            mems = self.memory[idx - (queue_size - 1):idx+session_size]\\n            counter_sess = 0 - (queue_size - 1)\\n            model.reset_queue()\\n            for mem in mems:\\n                state_t, action_t, reward_t, state_tp1 = mem[0]\\n                game_over = mem[1]\\n                inputs = state_t\\n                \\n                # There should be no target values for actions not taken.\\n                # Thou shalt not correct actions not taken #deep\\n                targets = model(state_t) # Variable\\n                counter_sess += 1\\n                if counter_sess >= 0:\\n                    temp_queue = model.save_queue()\\n                    Q_sa = model(state_tp1).data.max(1)[0].view(1, 1)\\n                    model.load_queue(temp_queue)\\n                    if game_over:  # if game_over is True\\n                        targets[0, action_t[0]] = Variable(reward_t)\\n                    else:\\n                        targets[0, action_t[0]] = Variable(Q_sa * self.discount + reward_t)\\n                    print(targets.size(), \"inputs\")\\n                    print(inputs.size(), \"inputs\")\\n                    if Oin is None:\\n                        Oin = inputs\\n                        Otar = targets\\n                    else:\\n                        Oin = torch.cat((Oin, inputs), 0)\\n                        Otar = torch.cat((Otar, targets), 0)\\n                \\n            \\n        return Oin, Otar\\n    \\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'reward', 'next_state'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, max_memory):\n",
    "        self.capacity = max_memory\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, session_size, queue_size):\n",
    "        idx = np.random.randint(queue_size, len(self.memory)-session_size)\n",
    "               \n",
    "        return self.memory[(idx-(queue_size - 1)):(idx+session_size)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    \n",
    "\"\"\"class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = []\n",
    "        self.discount = Tensor([discount])\n",
    "\n",
    "    def push(self, states, game_over):\n",
    "        self.memory.append([states, game_over])\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[0]\n",
    "\n",
    "\n",
    "    def sample(self, model, sessions=5, session_size=20, queue_size=1):\n",
    "        len_memory = len(self.memory)\n",
    "        num_actions = model.output_shape[-1]\n",
    "\n",
    "        Oin = None\n",
    "        Otar = None\n",
    "        \n",
    "        for i, idx in enumerate(np.random.randint(queue_size, len_memory-session_size,\n",
    "                                                  size=min(len_memory-session_size - queue_size, sessions))):\n",
    "\n",
    "            mems = self.memory[idx - (queue_size - 1):idx+session_size]\n",
    "            counter_sess = 0 - (queue_size - 1)\n",
    "            model.reset_queue()\n",
    "            for mem in mems:\n",
    "                state_t, action_t, reward_t, state_tp1 = mem[0]\n",
    "                game_over = mem[1]\n",
    "                inputs = state_t\n",
    "                \n",
    "                # There should be no target values for actions not taken.\n",
    "                # Thou shalt not correct actions not taken #deep\n",
    "                targets = model(state_t) # Variable\n",
    "                counter_sess += 1\n",
    "                if counter_sess >= 0:\n",
    "                    temp_queue = model.save_queue()\n",
    "                    Q_sa = model(state_tp1).data.max(1)[0].view(1, 1)\n",
    "                    model.load_queue(temp_queue)\n",
    "                    if game_over:  # if game_over is True\n",
    "                        targets[0, action_t[0]] = Variable(reward_t)\n",
    "                    else:\n",
    "                        targets[0, action_t[0]] = Variable(Q_sa * self.discount + reward_t)\n",
    "                    print(targets.size(), \"inputs\")\n",
    "                    print(inputs.size(), \"inputs\")\n",
    "                    if Oin is None:\n",
    "                        Oin = inputs\n",
    "                        Otar = targets\n",
    "                    else:\n",
    "                        Oin = torch.cat((Oin, inputs), 0)\n",
    "                        Otar = torch.cat((Otar, targets), 0)\n",
    "                \n",
    "            \n",
    "        return Oin, Otar\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        # Not sure if needed\\n        self.queue.requires_grad = False'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FifoQueue(Function):\n",
    "    \n",
    "    def forward(self, old_queue, inputs):\n",
    "        outputs = None\n",
    "        queue = old_queue.clone()\n",
    "        for temp in inputs:\n",
    "            queue = torch.cat((queue, temp.unsqueeze(0)), 0)\n",
    "            queue = queue[1:]\n",
    "            if outputs is None:\n",
    "                outputs = queue.clone().unsqueeze(0)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, queue.unsqueeze(0)), 0)\n",
    "        return outputs, queue\n",
    "\n",
    "    def backward(self, output_grad, bad_boi):\n",
    "        return bad_boi[-1], output_grad[:,-1]\n",
    "\n",
    "\n",
    "class Queue(nn.Module):\n",
    "    def __init__(self, input_features, out_features, queue_size, bias=None):\n",
    "        super(Queue, self).__init__()\n",
    "        # Setup the Queue\n",
    "        self.input_features = input_features\n",
    "        self.queue_size = queue_size\n",
    "        self.reset_queue()\n",
    "        \n",
    "        # Init the queue function\n",
    "        self.FifoQueue = FifoQueue()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # The actual call that is run when you pass data into this model. \n",
    "        output, self.queue = self.FifoQueue(self.queue, inputs)\n",
    "\n",
    "        # Linear layer built into this layer. \n",
    "        return output\n",
    "            \n",
    "    # reunit the queue\n",
    "    def reset_queue(self):\n",
    "        if type(self.input_features) is list:\n",
    "            queue = Variable(torch.zeros([self.queue_size]+self.input_features).type(FloatTensor))\n",
    "        else:\n",
    "            queue = Variable(torch.zeros([self.queue_size]+[self.input_features]).type(FloatTensor))\n",
    "        self.queue = queue\n",
    "\"\"\"        # Not sure if needed\n",
    "        self.queue.requires_grad = False\"\"\"\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Queued_DQN(nn.Module):\\n    def __init__(self, input_size, hidden_size, num_actions, queue_size):\\n        super(Queued_DQN, self).__init__()\\n        self.queue = Queue(input_size, input_size*queue_size, queue_size)\\n        #self.lin1 = nn.Linear(input_size*queue_size, hidden_size)\\n        self.lin2 = nn.Linear(hidden_size, hidden_size)\\n        self.lin3 = nn.Linear(hidden_size, num_actions)\\n        self.output_shape = [1, num_actions]\\n        \\n    def forward(self, x):\\n        # Replace queue with another Linear and you \\n        # have the same network we use for everything else. \\n        # This is the model\\n        x = F.relu(self.queue(x))\\n        #x = F.relu(self.lin1(x))\\n        x = F.relu(self.lin2(x))\\n        x = self.lin3(x)\\n        return x\\n    \\n    def reset_queue(self):\\n        self.queue.reset_queue()\\n        \\n    def save_queue(self):\\n        return self.queue.queue.clone()\\n        \\n    def load_queue(self, input_queue):\\n        self.queue.queue = input_queue.clone() '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Queued_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_actions, queue_size):\n",
    "        super(Queued_DQN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.queue = Queue(1296, 1296*queue_size, queue_size)\n",
    "        self.lin1 = nn.Linear(1296*queue_size, 1296*queue_size)\n",
    "        self.lin2 = nn.Linear(1296*queue_size, num_actions)\n",
    "        self.output_shape = [1, num_actions]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Replace queue with another Linear and you \n",
    "        # have the same network we use for everything else. \n",
    "        # This is the model\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.queue(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_queue(self):\n",
    "        self.queue.reset_queue()\n",
    "        \n",
    "    def save_queue(self):\n",
    "        return self.queue.queue.clone()\n",
    "        \n",
    "    def load_queue(self, input_queue):\n",
    "        self.queue.queue = input_queue.clone()\n",
    "        \n",
    "\"\"\"class Queued_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_actions, queue_size):\n",
    "        super(Queued_DQN, self).__init__()\n",
    "        self.queue = Queue(input_size, input_size*queue_size, queue_size)\n",
    "        #self.lin1 = nn.Linear(input_size*queue_size, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3 = nn.Linear(hidden_size, num_actions)\n",
    "        self.output_shape = [1, num_actions]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Replace queue with another Linear and you \n",
    "        # have the same network we use for everything else. \n",
    "        # This is the model\n",
    "        x = F.relu(self.queue(x))\n",
    "        #x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_queue(self):\n",
    "        self.queue.reset_queue()\n",
    "        \n",
    "    def save_queue(self):\n",
    "        return self.queue.queue.clone()\n",
    "        \n",
    "    def load_queue(self, input_queue):\n",
    "        self.queue.queue = input_queue.clone() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def train_catch(catch, model, exp_replay, num_games, session_size, sessions,\n",
    "                per_random_act=.1, num_actions=3, queue_size=1, \n",
    "                test_every=None, test_on_games=100, discount=.9):\n",
    "    \n",
    "    # Pytorch Adagrad Optimizer linked with the model\n",
    "    optimizer = optim.Adagrad(model.parameters())\n",
    "\n",
    "    # Set up the return Loss and Scores dataframes\n",
    "    rLoss = pd.DataFrame(columns = ['epoch', 'loss'])\n",
    "    rLoss['epoch'] = rLoss['epoch'].astype(int)\n",
    "\n",
    "    if test_every is not None:\n",
    "        rScores = pd.DataFrame(columns = ['epoch', str('mean score over ' + str(test_on_games) + ' games')])\n",
    "        rScores['epoch'] = rLoss['epoch'].astype(int)\n",
    "        \n",
    "    # Record variables for training\n",
    "    game_cnt = 0\n",
    "    timestep = 0.0\n",
    "    counter = 0\n",
    "    after_first_ball = False\n",
    "    \n",
    "    pushed = 0\n",
    "    \n",
    "    #train over total epochs\n",
    "    for e in range(num_games):\n",
    "\n",
    "        game_over = False\n",
    "        tot_loss = 0.0\n",
    "\n",
    "        # get initial input\n",
    "        input_t = Tensor(catch.observe(flatten=False, expand_dim=True))\n",
    "    \n",
    "        #iterate over each game\n",
    "        while not game_over:\n",
    "            # t_-1 is the previous observation\n",
    "            input_tm1 = input_t.clone()\n",
    "            \n",
    "            # Calculate next action\n",
    "            q = model(Variable(input_tm1, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
    "            \n",
    "            # Randomly pick an action, or use the \n",
    "            # Preciously calculated action\n",
    "            if np.random.rand() <= per_random_act:\n",
    "                action = (torch.rand(1) * (num_actions)).type(LongTensor)\n",
    "            else:\n",
    "                action = q.type(LongTensor)[0]\n",
    "                \n",
    "            # apply action, get rewards and new state\n",
    "            reward, timestep, game_over = catch.act(action.numpy()[0]-1)\n",
    "            # t_0, current timestep\n",
    "            input_t = Tensor(catch.observe(flatten=False, expand_dim=True))\n",
    "            \n",
    "            # store experience\n",
    "            exp_replay.push(input_tm1, action, Tensor([reward]), input_t)\n",
    "            \n",
    "            # game has completed, add one to the total game count\n",
    "            if game_over:\n",
    "                game_cnt += 1\n",
    "                \n",
    "            pushed = pushed + 1\n",
    "                \n",
    "            # adapt model\n",
    "            if pushed >= session_size*sessions*2 + 1: \n",
    "                temp_queue = model.save_queue()\n",
    "                for pep in range(sessions):\n",
    "                    model.reset_queue()\n",
    "                    transitions = exp.sample(session_size, queue_size)\n",
    "\n",
    "                    batch = Transition(*zip(*transitions))\n",
    "\n",
    "                    non_final_mask = ByteTensor(tuple(map(lambda s: s is not None,\n",
    "                                                          batch.next_state)))\n",
    "\n",
    "                    \n",
    "                    non_final_next_states = Variable(torch.cat([s for s in batch.next_state\n",
    "                                                                if s is not None]),\n",
    "                                                     volatile=True)\n",
    "                    \n",
    "                    state_batch = Variable(torch.cat(batch.state))\n",
    "                    action_batch = Variable(torch.cat(batch.action))\n",
    "                    reward_batch = Variable(torch.cat(batch.reward))\n",
    "\n",
    "                    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "                    # columns of actions taken\n",
    "                    state_action_values = model(state_batch).gather(1, action_batch.unsqueeze(-1))\n",
    "\n",
    "                    # Compute V(s_{t+1}) for all next states.\n",
    "                    next_state_values = Variable(torch.zeros(session_size+(queue_size-1)).type(Tensor))\n",
    "                                      \n",
    "                    next_state_values[non_final_mask] = model(non_final_next_states).max(1)[0]\n",
    "                    # Now, we don't want to mess up the loss with a volatile flag, so let's\n",
    "                    # clear it. After this, we'll just end up with a Variable that has\n",
    "                    # requires_grad=False\n",
    "                    next_state_values.volatile = False\n",
    "\n",
    "                    # Compute the expected Q values\n",
    "                    expected_state_action_values = (next_state_values * discount) + reward_batch\n",
    "\n",
    "                    # Compute Huber loss\n",
    "                    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "                    tot_loss = tot_loss + loss.data.numpy()[0]\n",
    "\n",
    "                    # Optimize the model\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    for param in model.parameters():\n",
    "                        if param.grad is not None:\n",
    "                            param.grad.data.clamp_(-1, 1)\n",
    "                    optimizer.step()\n",
    "\n",
    "                model.load_queue(temp_queue)\n",
    "\n",
    "            \n",
    "\n",
    "        if pushed >= session_size*sessions*2 + 1:\n",
    "            # Save and report loss\n",
    "            rLoss.loc[len(rLoss), :] = [int(e),loss]\n",
    "            print(\"Epoch {:03d} | Loss {:.4f}\".format(e, tot_loss))\n",
    "            # Create initial start environment\n",
    "            \n",
    "        # Reset Game and Model Queue when the game is over. \n",
    "        catch.reset()\n",
    "        model.reset_queue()\n",
    "        \n",
    "        # Test the current model weights if need be.\n",
    "        if (test_every is not None) and ((e + 1) % test_every == 0):\n",
    "\n",
    "            scores = test_catch(\n",
    "                catch=catch, model=model, \n",
    "                test_on_games=test_on_games)\n",
    "\n",
    "            # Save and report mean Score\n",
    "            ms = scores['score'].mean()\n",
    "            rScores.loc[len(rScores), :] = [int(e), ms]\n",
    "            print(\"Epoch {:03d} | MeanScore {:.2f}\".format(e, ms))\n",
    "\n",
    "            catch.reset()\n",
    "\n",
    "    # Return rLoss, and rScores if the user requested the model to be tested\n",
    "    # while training.\n",
    "    if (test_every is not None):\n",
    "        return rLoss, rScores\n",
    "    else:\n",
    "        return rLoss\n",
    "\n",
    "\n",
    "\n",
    "def test_catch(catch, model, test_on_games=100,  save_frames=False):\n",
    "\n",
    "    if save_frames:\n",
    "        frames_stack = []\n",
    "    scores = pd.DataFrame(columns=['game', 'score'])\n",
    "    scores['game'] = scores['game'].astype(int)\n",
    "    # Iterate over number of games to play\n",
    "    for game_num in range(test_on_games):\n",
    "\n",
    "        # Count for num balls that reached the end\n",
    "        game_over = False\n",
    "\n",
    "        # Get initial Frame\n",
    "        frame_num = 1\n",
    "        input_t = Tensor(catch.observe(flatten=False, expand_dim=True))\n",
    "        if save_frames:\n",
    "            frames_stack.append(input_t)\n",
    "\n",
    "        total_score = 0\n",
    "        # Iterate until end of testing game\n",
    "        while not game_over:\n",
    "\n",
    "            input_tm1 = input_t.clone()\n",
    "\n",
    "            # Get next action\n",
    "            q = model(Variable(input_tm1, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
    "            action = q.numpy()[0][0]\n",
    "\n",
    "            # apply action, get rewards and new state\n",
    "            reward, timestep, game_over = catch.act(action-1)\n",
    "            input_t = Tensor(catch.observe(flatten=False, expand_dim=True))\n",
    "            total_score += reward\n",
    "            # Iterate frame number\n",
    "            frame_num += 1\n",
    "\n",
    "            if save_frames:\n",
    "                frames_stack.append(input_t)\n",
    "                \n",
    "        scores.loc[len(scores), :] = [int(game_num), total_score]\n",
    "        #scores.append([game_num, total_score])\n",
    "        game_num += 1\n",
    "        catch.reset()\n",
    "        model.reset_queue()\n",
    "\n",
    "    if save_frames:\n",
    "        return scores, frames_stack\n",
    "    else:\n",
    "        return scores\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonjacques/anaconda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "sess_size=10\n",
    "sess = 5\n",
    "\n",
    "q_size = 4\n",
    "i=0\n",
    "\n",
    "test_name = \"RUN\" + str(i) + \"_Q\" + str(q_size)+\"_breakout\"\n",
    "\n",
    "breakout = ale.AleEnv(\"breakout.a26\", game_over_conditions={\"lives\":2, \"episodes\":200}, \n",
    "                      frame_skip=4, screen_color='gray', \n",
    "                      min_action_set=True, reduce_screen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 84 4\n"
     ]
    }
   ],
   "source": [
    "exp = ReplayMemory(max_memory=1000)\n",
    "\n",
    "width = breakout.width\n",
    "height = breakout.height\n",
    "\n",
    "num_actions = len(breakout.actions)\n",
    "\n",
    "print(width, height, num_actions)\n",
    "\n",
    "hidden_size = width * height\n",
    "\n",
    "model = Queued_DQN(hidden_size, hidden_size*q_size, num_actions, q_size)\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakout.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonjacques/anaconda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss 1289.1372\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-b485eed1dfc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m loss, test_on_train = train_catch(catch = breakout, model = model, exp_replay = exp, num_games = 500, per_random_act=.33,\n\u001b[0;32m----> 2\u001b[0;31m                                   test_every = 50, test_on_games = 100, session_size=sess_size, sessions=sess, queue_size=q_size)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbreakout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_catch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreakout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_on_games\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-35d8127b61f5>\u001b[0m in \u001b[0;36mtrain_catch\u001b[0;34m(catch, model, exp_replay, num_games, session_size, sessions, per_random_act, num_actions, queue_size, test_every, test_on_games, discount)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/optim/adagrad.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_values\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss, test_on_train = train_catch(catch = breakout, model = model, exp_replay = exp, num_games = 500, per_random_act=.33,\n",
    "                                  test_every = 50, test_on_games = 100, session_size=sess_size, sessions=sess, queue_size=q_size)\n",
    "breakout.reset()\n",
    "\n",
    "tests = test_catch(catch = breakout, model = model, test_on_games = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\".//configs\", exist_ok=True)\n",
    "os.makedirs(\".//data\", exist_ok=True)\n",
    "os.makedirs(\".//figs\", exist_ok=True)\n",
    "\n",
    "torch.save(model, \"configs//\" + test_name + \".pt\")\n",
    "loss.to_csv(\"data//\" + test_name + \"_loss.csv\", index=False)\n",
    "test_on_train.to_csv(\"data//\" + test_name + \"_tests_in_training.csv\", index=False)\n",
    "tests.to_csv(\"data//\" + test_name + \"_tests.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"configs//\" + test_name + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       " array([[-0.01113155,  0.02911727, -0.00065977,  0.00394386],\n",
       "        [-0.02103461, -0.02210965,  0.0265988 ,  0.00849212],\n",
       "        [-0.02237904, -0.02285606,  0.02704065,  0.0142559 ],\n",
       "        [-0.02158727, -0.02220373,  0.02559841,  0.0099347 ],\n",
       "        [-0.02230541, -0.02113417,  0.03136184,  0.01512389],\n",
       "        [-0.01932661, -0.02191391,  0.02813921,  0.01295937],\n",
       "        [-0.00233078,  0.00089694,  0.02813921,  0.00447616]], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.sample(model, \n",
    "          sessions=sess, \n",
    "          session_size=sess_size, \n",
    "          queue_size=q_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  True],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "exp.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False], [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False], [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(q_size, len(exp.memory)-sess_size,\n",
    "                                                  size=min(len(exp.memory)-sess_size - q_size, sess)):\n",
    "    print(exp.memory[i - (q_size - 1):i - (q_size - 1)+sess_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 35, 54, 21, 88])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(q_size, len(exp.memory)-sess_size,\n",
    "                                                  size=min(len(exp.memory)-sess_size - q_size, sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = nn.Conv2d(16, 32, kernel_size=4, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakout.observe(flatten=False, expand_dim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
