{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, Function\n",
    "import torchvision.transforms as T\n",
    "import ale\n",
    "\n",
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, max_memory=100, discount=.9):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = []\n",
    "        self.discount = discount\n",
    "\n",
    "    def push(self, states, game_over):\n",
    "        self.memory.append([states, game_over])\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[0]\n",
    "\n",
    "\n",
    "    def sample(self, model, sessions=5, session_size=20, queue_size=1):\n",
    "        len_memory = len(self.memory)\n",
    "        num_actions = model.output_shape[-1]\n",
    "\n",
    "        Oin = None\n",
    "        Otar = None\n",
    "        \n",
    "        for i, idx in enumerate(np.random.randint(queue_size, len_memory-session_size,\n",
    "                                                  size=min(len_memory-session_size - queue_size, sessions))):\n",
    "\n",
    "            mems = self.memory[idx - (queue_size - 1):idx+session_size]\n",
    "            counter_sess = 0 - (queue_size - 1)\n",
    "            model.reset_queue()\n",
    "            for mem in mems:\n",
    "                state_t, action_t, reward_t, state_tp1 = mem[0]\n",
    "                game_over = mem[1]\n",
    "                inputs = state_t\n",
    "                temp_state_t = Variable(torch.from_numpy(state_t).type(Tensor))\n",
    "                temp_state_tp1 = Variable(torch.from_numpy(state_tp1).type(Tensor))\n",
    "                \n",
    "                # There should be no target values for actions not taken.\n",
    "                # Thou shalt not correct actions not taken #deep\n",
    "                targets = model(temp_state_t).data.numpy()[0]\n",
    "                counter_sess += 1\n",
    "                if counter_sess >= 0:\n",
    "                    temp_queue = model.save_queue()\n",
    "                    Q_sa = model(temp_state_tp1).data.max(1)[0].view(1, 1).numpy()[0][0]\n",
    "                    model.load_queue(temp_queue)\n",
    "\n",
    "                    if game_over:  # if game_over is True\n",
    "                        targets[action_t] = reward_t\n",
    "                    else:\n",
    "                        # reward_t + gamma * max_a' Q(s', a')\n",
    "                        targets[action_t] = reward_t + self.discount * Q_sa\n",
    "                    if Oin is None:\n",
    "                        Oin = inputs\n",
    "                        Otar = np.expand_dims(targets, axis=0)\n",
    "                    else:\n",
    "                        Oin = np.concatenate([Oin, inputs], axis=0)\n",
    "                        Otar = np.concatenate([Otar, np.expand_dims(targets, axis=0)], axis=0)\n",
    "                \n",
    "            \n",
    "        return Oin, Otar\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class fifo_queue(Function):\n",
    "    def forward(self, old_queue, inputs):\n",
    "        outputs = None\n",
    "        queue = old_queue.clone()\n",
    "        for temp in inputs:\n",
    "            queue = torch.cat((queue, temp.unsqueeze(0)), 0)\n",
    "            queue = queue[1:]\n",
    "            if outputs is None:\n",
    "                outputs = queue.clone().unsqueeze(0)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, queue.unsqueeze(0)), 0)\n",
    "        return outputs, queue\n",
    "    \n",
    "    def backward(self, output_grad, bad_boi):\n",
    "        \n",
    "        # I DONT KNOW WHAT BAD BOI DOES\n",
    "        #print(bad_boi)\n",
    "        return bad_boi[-1], output_grad[:,-1]\n",
    "\n",
    "\n",
    "class Queue(nn.Module):\n",
    "    def __init__(self, input_features, out_features, queue_size, bias=None):\n",
    "        super(Queue, self).__init__()\n",
    "        # Setup the Queue\n",
    "        self.input_features = input_features\n",
    "        self.queue_size = queue_size\n",
    "        self.reset_queue()\n",
    "        \n",
    "        # Init the queue function\n",
    "        self.fifo_queue = fifo_queue()\n",
    "\n",
    "        # Setup the weights to be used in the linear function later. \n",
    "        self.weight = Parameter(torch.Tensor(out_features, input_features*queue_size).type(FloatTensor))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features).type(FloatTensor))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        # Init the parameters\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        # The actual call that is run when you pass data into this model. \n",
    "        output, self.queue = self.fifo_queue(self.queue, inputs)\n",
    "        \n",
    "        #Flatten the queue\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        \n",
    "        # Linear layer built into this layer. \n",
    "        return F.linear(output, self.weight, self.bias)\n",
    "            \n",
    "    # reunit the queue\n",
    "    def reset_queue(self):\n",
    "        \n",
    "        if type(self.input_features) is list:\n",
    "            queue = Variable(torch.zeros([self.queue_size]+self.input_features).type(FloatTensor))\n",
    "        else:\n",
    "            queue = Variable(torch.zeros([self.queue_size]+[self.input_features]).type(FloatTensor))\n",
    "        self.queue = queue\n",
    "        # Not sure if needed\n",
    "        self.queue.requires_grad = False\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Queued_DQN(nn.Module):\\n    def __init__(self, input_size, hidden_size, num_actions, queue_size):\\n        super(Queued_DQN, self).__init__()\\n        self.queue = Queue(input_size, input_size*queue_size, queue_size)\\n        #self.lin1 = nn.Linear(input_size*queue_size, hidden_size)\\n        self.lin2 = nn.Linear(hidden_size, hidden_size)\\n        self.lin3 = nn.Linear(hidden_size, num_actions)\\n        self.output_shape = [1, num_actions]\\n        \\n    def forward(self, x):\\n        # Replace queue with another Linear and you \\n        # have the same network we use for everything else. \\n        # This is the model\\n        x = F.relu(self.queue(x))\\n        #x = F.relu(self.lin1(x))\\n        x = F.relu(self.lin2(x))\\n        x = self.lin3(x)\\n        return x\\n    \\n    def reset_queue(self):\\n        self.queue.reset_queue()\\n        \\n    def save_queue(self):\\n        return self.queue.queue.clone()\\n        \\n    def load_queue(self, input_queue):\\n        self.queue.queue = input_queue.clone() '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Queued_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_actions, queue_size):\n",
    "        super(Queued_DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.queue = Queue(1296, 1296*queue_size, queue_size)\n",
    "        #self.lin1 = nn.Linear(input_size*queue_size, hidden_size)\n",
    "        #self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3 = nn.Linear(1296*queue_size, num_actions)\n",
    "        self.output_shape = [1, num_actions]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Replace queue with another Linear and you \n",
    "        # have the same network we use for everything else. \n",
    "        # This is the model\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.queue(x))\n",
    "        #x = F.relu(self.lin1(x))\n",
    "        #x = F.relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_queue(self):\n",
    "        self.queue.reset_queue()\n",
    "        \n",
    "    def save_queue(self):\n",
    "        return self.queue.queue.clone()\n",
    "        \n",
    "    def load_queue(self, input_queue):\n",
    "        self.queue.queue = input_queue.clone()\n",
    "        \n",
    "\"\"\"class Queued_DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_actions, queue_size):\n",
    "        super(Queued_DQN, self).__init__()\n",
    "        self.queue = Queue(input_size, input_size*queue_size, queue_size)\n",
    "        #self.lin1 = nn.Linear(input_size*queue_size, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3 = nn.Linear(hidden_size, num_actions)\n",
    "        self.output_shape = [1, num_actions]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Replace queue with another Linear and you \n",
    "        # have the same network we use for everything else. \n",
    "        # This is the model\n",
    "        x = F.relu(self.queue(x))\n",
    "        #x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_queue(self):\n",
    "        self.queue.reset_queue()\n",
    "        \n",
    "    def save_queue(self):\n",
    "        return self.queue.queue.clone()\n",
    "        \n",
    "    def load_queue(self, input_queue):\n",
    "        self.queue.queue = input_queue.clone() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def train_catch(catch, model, exp_replay, num_games, session_size, sessions,\n",
    "                per_random_act=.1, num_actions=3, queue_size=1, \n",
    "                test_every=None, test_on_games=100):\n",
    "    \n",
    "    # Pytorch Adagrad Optimizer linked with the model\n",
    "    optimizer = optim.Adagrad(model.parameters())\n",
    "\n",
    "    # Set up the return Loss and Scores dataframes\n",
    "    rLoss = pd.DataFrame(columns = ['epoch', 'loss'])\n",
    "    rLoss['epoch'] = rLoss['epoch'].astype(int)\n",
    "\n",
    "    if test_every is not None:\n",
    "        rScores = pd.DataFrame(columns = ['epoch', str('mean score over ' + str(test_on_games) + ' games')])\n",
    "        rScores['epoch'] = rLoss['epoch'].astype(int)\n",
    "        \n",
    "    # Record variables for training\n",
    "    game_cnt = 0\n",
    "    timestep = 0.0\n",
    "    counter = 0\n",
    "    after_first_ball = False\n",
    "    \n",
    "    pushed = 0\n",
    "    \n",
    "    #train over total epochs\n",
    "    for e in range(num_games):\n",
    "\n",
    "        game_over = False\n",
    "        tot_loss = 0.0\n",
    "\n",
    "        # get initial input\n",
    "        input_t = catch.observe(flatten=False, expand_dim=True)\n",
    "    \n",
    "        #iterate over each game\n",
    "        while not game_over:\n",
    "            # t_-1 is the previous observation\n",
    "            input_tm1 = input_t.copy()\n",
    "            \n",
    "            # Calculate next action\n",
    "            temp = torch.from_numpy(input_tm1).type(Tensor)\n",
    "            temp = Variable(temp)\n",
    "            q = model(temp).data.max(1)[1].view(1, 1).numpy()\n",
    "            \n",
    "            # Randomly pick an action, or use the \n",
    "            # Preciously calculated action\n",
    "            if np.random.rand() <= per_random_act:\n",
    "                action = torch.rand(1) * (num_actions)\n",
    "                action = int(action.numpy()[0])\n",
    "            else:\n",
    "                action = q[0][0]\n",
    "                \n",
    "            # apply action, get rewards and new state\n",
    "            reward, timestep, game_over = catch.act(action-1)\n",
    "            # t_0, current timestep\n",
    "            input_t = catch.observe(flatten=False, expand_dim=True)\n",
    "            \n",
    "            # store experience\n",
    "            exp_replay.push(states=[input_tm1, action, reward, input_t], game_over=game_over)\n",
    "            # game has completed, add one to the total game count\n",
    "            if game_over:\n",
    "                game_cnt += 1\n",
    "                \n",
    "            pushed = pushed + 1\n",
    "                \n",
    "            # adapt model\n",
    "            if pushed >= session_size*sessions*2 + 1: \n",
    "                temp_queue = model.save_queue()\n",
    "                \n",
    "                model.reset_queue()\n",
    "                inputs, expected_targets = exp_replay.sample(model, \n",
    "                                                             sessions=sessions, \n",
    "                                                             session_size=session_size, \n",
    "                                                             queue_size=queue_size)\n",
    "\n",
    "                model.reset_queue()\n",
    "                targets = model(Variable(torch.from_numpy(inputs).type(FloatTensor)))\n",
    "\n",
    "                expected_targets = Variable(torch.from_numpy(expected_targets).type(FloatTensor))\n",
    "                \n",
    "                # Compute Huber loss\n",
    "                loss = F.smooth_l1_loss(targets, expected_targets)\n",
    "                tot_loss = tot_loss + loss.data.numpy()[0]\n",
    "                # Optimize the model\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-1, 1)\n",
    "                optimizer.step()\n",
    "\n",
    "                model.load_queue(temp_queue)\n",
    "\n",
    "            \n",
    "\n",
    "        if pushed >= session_size*sessions*2 + 1:\n",
    "            # Save and report loss\n",
    "            rLoss.loc[len(rLoss), :] = [int(e),loss]\n",
    "            print(\"Epoch {:03d} | Loss {:.4f}\".format(e, tot_loss))\n",
    "            # Create initial start environment\n",
    "            \n",
    "        # Reset Game and Model Queue when the game is over. \n",
    "        catch.reset()\n",
    "        model.reset_queue()\n",
    "        \n",
    "        # Test the current model weights if need be.\n",
    "        if (test_every is not None) and ((e + 1) % test_every == 0):\n",
    "\n",
    "            scores = test_catch(\n",
    "                catch=catch, model=model, \n",
    "                test_on_games=test_on_games)\n",
    "\n",
    "            # Save and report mean Score\n",
    "            ms = scores['score'].mean()\n",
    "            rScores.loc[len(rScores), :] = [int(e), ms]\n",
    "            print(\"Epoch {:03d} | MeanScore {:.2f}\".format(e, ms))\n",
    "\n",
    "            catch.reset()\n",
    "\n",
    "    # Return rLoss, and rScores if the user requested the model to be tested\n",
    "    # while training.\n",
    "    if (test_every is not None):\n",
    "        return rLoss, rScores\n",
    "    else:\n",
    "        return rLoss\n",
    "\n",
    "\n",
    "\n",
    "def test_catch(catch, model, test_on_games=100,  save_frames=False):\n",
    "\n",
    "    if save_frames:\n",
    "        frames_stack = []\n",
    "    scores = pd.DataFrame(columns=['game', 'score'])\n",
    "    scores['game'] = scores['game'].astype(int)\n",
    "    # Iterate over number of games to play\n",
    "    for game_num in range(test_on_games):\n",
    "\n",
    "        # Count for num balls that reached the end\n",
    "        game_over = False\n",
    "\n",
    "        # Get initial Frame\n",
    "        frame_num = 1\n",
    "        input_t = catch.observe(flatten=False, expand_dim=True)\n",
    "        if save_frames:\n",
    "            frames_stack.append(input_t)\n",
    "\n",
    "        total_score = 0\n",
    "        # Iterate until end of testing game\n",
    "        while not game_over:\n",
    "\n",
    "            input_tm1 = input_t\n",
    "\n",
    "            # Get next action\n",
    "            temp = torch.from_numpy(input_tm1).type(FloatTensor)\n",
    "            temp = Variable(temp)\n",
    "            q = model(temp).data.max(1)[1].view(1, 1).numpy()\n",
    "            action = q[0][0]\n",
    "\n",
    "            # apply action, get rewards and new state\n",
    "            reward, timestep, game_over = catch.act(action-1)\n",
    "            input_t = catch.observe(flatten=False, expand_dim=True)\n",
    "            total_score += reward\n",
    "            # Iterate frame number\n",
    "            frame_num += 1\n",
    "\n",
    "            if save_frames:\n",
    "                frames_stack.append(input_t)\n",
    "                \n",
    "        scores.loc[len(scores), :] = [int(game_num), total_score]\n",
    "        #scores.append([game_num, total_score])\n",
    "        game_num += 1\n",
    "        catch.reset()\n",
    "        model.reset_queue()\n",
    "\n",
    "    if save_frames:\n",
    "        return scores, frames_stack\n",
    "    else:\n",
    "        return scores\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonjacques/anaconda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "sess_size=10\n",
    "sess = 5\n",
    "\n",
    "q_size = 4\n",
    "i=0\n",
    "\n",
    "test_name = \"RUN\" + str(i) + \"_Q\" + str(q_size)+\"_breakout\"\n",
    "\n",
    "breakout = ale.AleEnv(\"breakout.a26\", game_over_conditions={\"lives\":2,\"episodes\":200}, \n",
    "                      frame_skip=4, screen_color='gray', \n",
    "                      min_action_set=True, reduce_screen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 84 4\n"
     ]
    }
   ],
   "source": [
    "exp = ReplayMemory(max_memory=1000)\n",
    "\n",
    "width = breakout.width\n",
    "height = breakout.height\n",
    "\n",
    "num_actions = len(breakout.actions)\n",
    "\n",
    "print(width, height, num_actions)\n",
    "\n",
    "hidden_size = width * height\n",
    "\n",
    "model = Queued_DQN(hidden_size, hidden_size*q_size, num_actions, q_size)\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakout.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonjacques/anaconda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00249497\n",
      "41.4586\n",
      "21.2375\n",
      "9.88286\n",
      "4.38765\n",
      "1.96519\n",
      "2.66817\n",
      "0.478674\n",
      "1.27565\n",
      "1.86485\n",
      "0.749887\n",
      "0.741864\n",
      "0.468435\n",
      "1.03654\n",
      "0.957595\n",
      "0.686066\n",
      "0.181511\n",
      "1.05055\n",
      "0.109407\n",
      "0.116305\n",
      "0.475922\n",
      "0.393975\n",
      "0.817119\n",
      "0.384679\n",
      "0.603081\n",
      "0.341024\n",
      "0.407516\n",
      "0.347734\n",
      "0.389207\n",
      "0.216711\n",
      "0.145703\n",
      "0.104163\n",
      "0.0432524\n",
      "0.0626934\n",
      "0.0847094\n",
      "0.0893554\n",
      "0.058474\n",
      "0.0342401\n",
      "0.0476985\n",
      "0.0283665\n",
      "0.0252532\n",
      "0.0364129\n",
      "0.0263957\n",
      "0.0385298\n",
      "0.0670734\n",
      "0.0368326\n",
      "0.0780257\n",
      "0.0664782\n",
      "0.107581\n",
      "0.0671246\n",
      "0.102414\n",
      "0.129534\n",
      "0.332543\n",
      "0.325352\n",
      "0.217738\n",
      "0.115127\n",
      "0.148118\n",
      "0.145635\n",
      "0.0836736\n",
      "0.0545976\n",
      "0.0202\n",
      "0.0251818\n",
      "0.0308596\n",
      "0.0235939\n",
      "0.0261921\n",
      "0.0207812\n",
      "0.0393408\n",
      "0.0203481\n",
      "0.221261\n",
      "0.0453115\n",
      "0.0255554\n",
      "0.0264951\n",
      "0.0245822\n",
      "0.029772\n",
      "0.0586472\n",
      "0.0369135\n",
      "0.0270346\n",
      "0.0238244\n",
      "Epoch 000 | Loss 99.3257\n",
      "0.00993178\n",
      "0.0200279\n",
      "0.0176533\n",
      "0.0102303\n",
      "0.0209631\n",
      "0.0183429\n",
      "0.0376913\n",
      "0.0241572\n",
      "0.00883811\n",
      "0.00400316\n",
      "0.0138804\n",
      "0.00924591\n",
      "0.011604\n",
      "0.00524222\n",
      "0.00802314\n",
      "0.00683238\n",
      "0.0160283\n",
      "0.0148499\n",
      "0.0107742\n",
      "0.014321\n",
      "0.0113775\n",
      "0.0114827\n",
      "0.00949644\n",
      "0.00404158\n",
      "0.00508125\n",
      "0.00694445\n",
      "0.009582\n",
      "0.00658625\n",
      "0.0126471\n",
      "0.00895544\n",
      "0.00236758\n",
      "0.00564293\n",
      "0.0104557\n",
      "0.00397642\n",
      "0.0111833\n",
      "0.0176524\n",
      "0.00773531\n",
      "0.0275226\n",
      "0.014651\n",
      "0.00906647\n",
      "0.00704913\n",
      "0.0036823\n",
      "0.00602131\n",
      "0.00321563\n",
      "0.00817378\n",
      "0.00398279\n",
      "0.00350244\n",
      "0.00406604\n",
      "0.00444437\n",
      "0.00476625\n",
      "0.0155438\n",
      "0.0240063\n",
      "0.00842353\n",
      "0.0106191\n",
      "0.00641914\n",
      "0.00394121\n",
      "0.00838209\n",
      "0.00543423\n",
      "0.00854933\n",
      "0.00451128\n",
      "0.00917332\n",
      "0.00547597\n",
      "0.00693054\n",
      "0.0166205\n",
      "0.00831396\n",
      "0.0594135\n",
      "0.0138669\n",
      "0.0105025\n",
      "0.00633334\n",
      "0.00478909\n",
      "0.00175924\n",
      "0.00623125\n",
      "0.0047172\n",
      "0.00590354\n",
      "0.00707084\n",
      "0.00222276\n",
      "0.00340231\n",
      "0.00314305\n",
      "0.00408516\n",
      "0.00479491\n",
      "0.00685549\n",
      "0.0120312\n",
      "0.00283688\n",
      "0.00666866\n",
      "0.00162609\n",
      "0.00563931\n",
      "0.064932\n",
      "0.0415312\n",
      "0.0852898\n",
      "0.0374233\n",
      "0.0116437\n",
      "0.0233963\n",
      "0.0245328\n",
      "0.0103903\n",
      "0.00896255\n",
      "0.00484027\n",
      "0.00711512\n",
      "0.00726227\n",
      "0.00674102\n",
      "0.0122052\n",
      "0.00833438\n",
      "0.00716016\n",
      "0.0065279\n",
      "0.00338832\n",
      "0.00586001\n",
      "0.0127391\n",
      "0.0122385\n",
      "0.0312077\n",
      "0.0413315\n",
      "0.0450815\n",
      "0.0496523\n",
      "0.0317292\n",
      "0.0146453\n",
      "0.00754594\n",
      "0.0137929\n",
      "0.0115915\n",
      "0.0086542\n",
      "0.00868476\n",
      "0.00876828\n",
      "0.0141931\n",
      "0.0247537\n",
      "0.00490472\n",
      "0.0132228\n",
      "0.00999774\n",
      "0.005829\n",
      "0.0104439\n",
      "0.00505698\n",
      "0.0105096\n",
      "0.0150205\n",
      "0.00870419\n",
      "0.00434954\n",
      "0.00564104\n",
      "0.0106839\n",
      "0.0436887\n",
      "0.193691\n",
      "0.0078332\n",
      "0.00747359\n",
      "0.0181703\n",
      "0.00648616\n",
      "0.00583449\n",
      "0.00600346\n",
      "0.00809461\n",
      "0.00624515\n",
      "0.00793166\n",
      "0.00917721\n",
      "0.00476168\n",
      "0.00435542\n",
      "0.00485823\n",
      "0.00974474\n",
      "0.0110664\n",
      "0.00433592\n",
      "0.00746452\n",
      "0.00958623\n",
      "0.00398127\n",
      "0.00355827\n",
      "0.00226407\n",
      "0.00374411\n",
      "0.00230475\n",
      "0.00497224\n",
      "0.0063928\n",
      "0.0100243\n",
      "0.00515337\n",
      "0.0042532\n",
      "0.0034347\n",
      "0.0044968\n",
      "0.0013996\n",
      "0.00302591\n",
      "0.0069408\n",
      "0.00501967\n",
      "0.00801847\n",
      "0.00229602\n",
      "0.00434102\n",
      "0.00380715\n",
      "0.00305917\n",
      "0.00678206\n",
      "0.00555372\n",
      "0.00249717\n",
      "0.00699534\n",
      "0.00420279\n",
      "0.00311639\n",
      "0.00599538\n",
      "0.00521011\n",
      "0.00710909\n",
      "0.00539053\n",
      "0.00543891\n",
      "0.00636569\n",
      "0.00244397\n",
      "0.0083873\n",
      "0.00469097\n",
      "0.00496199\n",
      "0.00690196\n",
      "0.00628548\n",
      "0.00886336\n",
      "0.0106665\n",
      "0.00581084\n",
      "0.0208194\n",
      "0.00890527\n",
      "0.00403784\n",
      "0.00378682\n",
      "0.00661466\n",
      "0.0144422\n",
      "0.00997673\n",
      "0.0127244\n",
      "0.00617394\n",
      "0.0274937\n",
      "0.03295\n",
      "0.0516147\n",
      "0.0194033\n",
      "0.0203087\n",
      "0.0906574\n",
      "0.341445\n",
      "0.285119\n",
      "0.838358\n",
      "0.12774\n",
      "Epoch 001 | Loss 4.1783\n",
      "0.233923\n",
      "0.246513\n",
      "0.469603\n",
      "0.187164\n",
      "0.836284\n",
      "0.338499\n",
      "1.1248\n",
      "0.305108\n",
      "0.415225\n",
      "0.488895\n",
      "0.325086\n",
      "0.508057\n",
      "0.379794\n",
      "0.497147\n",
      "0.458391\n",
      "0.388926\n",
      "0.242063\n",
      "0.489927\n",
      "0.560939\n",
      "0.527247\n",
      "0.621724\n",
      "0.308649\n",
      "0.196397\n",
      "0.195367\n",
      "0.240703\n",
      "0.114561\n",
      "0.187766\n",
      "0.0781264\n",
      "0.0684673\n",
      "0.125924\n",
      "0.111104\n",
      "0.104255\n",
      "0.262338\n",
      "0.148425\n",
      "0.0745428\n",
      "0.124865\n",
      "0.0621427\n",
      "0.05725\n",
      "0.123679\n",
      "0.1622\n",
      "0.131565\n",
      "0.197981\n",
      "0.0764391\n",
      "0.169847\n",
      "0.12433\n",
      "0.150395\n",
      "0.173894\n",
      "0.123067\n",
      "0.253105\n",
      "0.0698689\n",
      "0.0767127\n",
      "0.141916\n",
      "0.109743\n",
      "0.0510121\n",
      "0.0623933\n",
      "0.111982\n",
      "0.097297\n",
      "0.0988645\n",
      "0.0367839\n",
      "0.0577243\n",
      "0.166439\n",
      "0.0605112\n",
      "0.0875633\n",
      "0.0871362\n",
      "0.143394\n",
      "0.200862\n",
      "0.210679\n",
      "0.161088\n",
      "0.339118\n",
      "0.169461\n",
      "0.246835\n",
      "0.218116\n",
      "0.280007\n",
      "0.123781\n",
      "0.151109\n",
      "0.115867\n",
      "0.229929\n",
      "0.205514\n",
      "0.224157\n",
      "0.0910431\n",
      "0.137782\n",
      "0.107081\n",
      "0.0975856\n",
      "0.155254\n",
      "0.0581017\n",
      "0.0622005\n",
      "0.243305\n",
      "0.0718107\n",
      "0.180849\n",
      "0.260971\n",
      "0.102237\n",
      "0.129879\n",
      "0.331794\n",
      "0.244329\n",
      "0.37599\n",
      "0.114707\n",
      "0.08305\n",
      "0.149911\n",
      "0.100124\n",
      "0.0571043\n",
      "0.0500163\n",
      "0.0402861\n",
      "0.0670496\n",
      "0.130726\n",
      "0.124781\n",
      "0.175533\n",
      "0.161145\n",
      "0.142861\n",
      "Epoch 002 | Loss 22.1761\n",
      "0.140498\n",
      "0.162041\n",
      "0.164719\n",
      "0.110015\n",
      "0.204586\n",
      "0.156953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b485eed1dfc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m loss, test_on_train = train_catch(catch = breakout, model = model, exp_replay = exp, num_games = 500, per_random_act=.33,\n\u001b[0;32m----> 2\u001b[0;31m                                   test_every = 50, test_on_games = 100, session_size=sess_size, sessions=sess, queue_size=q_size)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbreakout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_catch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreakout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_on_games\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-81a029c2f255>\u001b[0m in \u001b[0;36mtrain_catch\u001b[0;34m(catch, model, exp_replay, num_games, session_size, sessions, per_random_act, num_actions, queue_size, test_every, test_on_games)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                                              \u001b[0msessions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                                              \u001b[0msession_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                                              queue_size=queue_size)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-71abf17ea7a1>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, model, sessions, session_size, queue_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# There should be no target values for actions not taken.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# Thou shalt not correct actions not taken #deep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_state_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mcounter_sess\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcounter_sess\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ff9a2c103385>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# This is the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     35\u001b[0m         return F.batch_norm(\n\u001b[1;32m     36\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             self.training, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brandonjacques/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m    637\u001b[0m                training=False, momentum=0.1, eps=1e-5):\n\u001b[1;32m    638\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss, test_on_train = train_catch(catch = breakout, model = model, exp_replay = exp, num_games = 500, per_random_act=.33,\n",
    "                                  test_every = 50, test_on_games = 100, session_size=sess_size, sessions=sess, queue_size=q_size)\n",
    "breakout.reset()\n",
    "\n",
    "tests = test_catch(catch = breakout, model = model, test_on_games = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\".//configs\", exist_ok=True)\n",
    "os.makedirs(\".//data\", exist_ok=True)\n",
    "os.makedirs(\".//figs\", exist_ok=True)\n",
    "\n",
    "torch.save(model, \"configs//\" + test_name + \".pt\")\n",
    "loss.to_csv(\"data//\" + test_name + \"_loss.csv\", index=False)\n",
    "test_on_train.to_csv(\"data//\" + test_name + \"_tests_in_training.csv\", index=False)\n",
    "tests.to_csv(\"data//\" + test_name + \"_tests.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"configs//\" + test_name + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       " array([[-0.01113155,  0.02911727, -0.00065977,  0.00394386],\n",
       "        [-0.02103461, -0.02210965,  0.0265988 ,  0.00849212],\n",
       "        [-0.02237904, -0.02285606,  0.02704065,  0.0142559 ],\n",
       "        [-0.02158727, -0.02220373,  0.02559841,  0.0099347 ],\n",
       "        [-0.02230541, -0.02113417,  0.03136184,  0.01512389],\n",
       "        [-0.01932661, -0.02191391,  0.02813921,  0.01295937],\n",
       "        [-0.00233078,  0.00089694,  0.02813921,  0.00447616]], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.sample(model, \n",
    "          sessions=sess, \n",
    "          session_size=sess_size, \n",
    "          queue_size=q_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  True],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   1,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   0,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False],\n",
       " [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]),\n",
       "   2,\n",
       "   0,\n",
       "   array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])],\n",
       "  False]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "exp.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False], [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False], [[array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]]), 2, 0, array([[ 1.,  1.,  1., ...,  0.,  0.,  0.]])], False]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(q_size, len(exp.memory)-sess_size,\n",
    "                                                  size=min(len(exp.memory)-sess_size - q_size, sess)):\n",
    "    print(exp.memory[i - (q_size - 1):i - (q_size - 1)+sess_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 35, 54, 21, 88])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(q_size, len(exp.memory)-sess_size,\n",
    "                                                  size=min(len(exp.memory)-sess_size - q_size, sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = nn.Conv2d(16, 32, kernel_size=4, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakout.observe(flatten=False, expand_dim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
